{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using MLP to Classify Political Party in Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw = pd.read_csv('twitter_data.csv')\n",
    "tweets = list(tw['text'])\n",
    "labels = list(tw['party'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "25821\n25821\n"
    }
   ],
   "source": [
    "print(len(tweets))\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local library housing tools to clean and process incoming twitter data\n",
    "import twittertextcleaner as ttc\n",
    "processed_tweets = []\n",
    "for tw in tweets: \n",
    "    processed_tweets.append(ttc.preprocess_tweet(tw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "25821\n25821\n"
    }
   ],
   "source": [
    "print(len(labels))\n",
    "print(len(processed_tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "democrat\nrepublican\n"
    }
   ],
   "source": [
    "print(labels[0])\n",
    "print(labels[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "dem_counts = Counter()\n",
    "rep_counts = Counter()\n",
    "total_counts = Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(processed_tweets)):\n",
    "    if(labels[i] == labels[0]):\n",
    "        for tw in processed_tweets[i].split(' '):\n",
    "            dem_counts[tw] += 1\n",
    "            total_counts[tw] += 1\n",
    "    else: \n",
    "        for tw in processed_tweets[i].split(' '):\n",
    "            rep_counts[tw] +=1\n",
    "            total_counts[tw] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Ten Most Common Dem words:\n\n\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[('’', 5583),\n ('trump', 2423),\n ('presid', 1950),\n ('rt', 1879),\n ('—', 1568),\n ('peopl', 1531),\n ('u', 1397),\n ('need', 1385),\n ('american', 1382),\n ('make', 1355)]"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "print('Ten Most Common Dem words:')\n",
    "print('\\n')\n",
    "dem_counts.most_common()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Its interesting to note that the democratic tweets are saying Trump most often. But using his name. I hypothesize that these tweets are about Trump. Whereas the results of the  republican tweets are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Ten Most Common Rep words:\n\n\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[('rt', 4422),\n ('’', 3915),\n ('presid', 2553),\n ('realdonaldtrump', 2179),\n ('american', 1743),\n ('amp', 1635),\n ('whitehous', 1357),\n ('today', 1103),\n ('obama', 1088),\n ('‘', 1013)]"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "print('Ten Most Common Rep words:')\n",
    "print('\\n')\n",
    "rep_counts.most_common()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using rt (retweet) and his handle as the most used word. I think its fair to speculate that the democratic tweets are commenting on Trump's opinions where as the republication tweets are repeating Trump's opinions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see how things change when we look at ratio vs count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create counter object to store ratios\n",
    "dem_rep_ratios = Counter()\n",
    "for term,cnt in list(total_counts.most_common()):\n",
    "    if(cnt > 50):\n",
    "        dem_rep_ratio = dem_counts[term] / float(rep_counts[term]+1)\n",
    "        dem_rep_ratios[term] = dem_rep_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "dem-to-rep ratio for 'rt' = 0.4248247795613837\ndem-to-rep ratio for 'great' = 0.36769394261424015\ndem-to-rep ratio for 'news' = 0.5891891891891892\ndem-to-rep ratio for 'wealth' = 9.7\ndem-to-rep ratio for 'health' = 2.942857142857143\n"
    }
   ],
   "source": [
    "# a word with a number or 1 or greater, more democrats have used it\n",
    "# a word, with a number under zero, more republicans have used it\n",
    "\n",
    "print(\"dem-to-rep ratio for 'rt' = {}\".format(dem_rep_ratios[\"rt\"]))\n",
    "print(\"dem-to-rep ratio for 'great' = {}\".format(dem_rep_ratios[\"great\"]))\n",
    "print(\"dem-to-rep ratio for 'news' = {}\".format(dem_rep_ratios[\"news\"]))\n",
    "print(\"dem-to-rep ratio for 'wealth' = {}\".format(dem_rep_ratios[\"wealth\"]))\n",
    "print(\"dem-to-rep ratio for 'health' = {}\".format(dem_rep_ratios[\"health\"]))\n",
    "#according to this, from the candidates I chosen, a republican is more likly to retweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tw,ratio in dem_rep_ratios.most_common():\n",
    "    dem_rep_ratios[tw] = np.log(ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[('teamjo', 5.717027701406222),\n ('—hillari', 4.969813299576001),\n ('demdeb', 4.859812404361672),\n ('jill', 4.836281906951478),\n ('lgbtq', 4.574710978503383),\n ('berniesand', 4.42484663185681),\n ('knock', 4.23410650459726),\n ('oneterm', 4.189654742026425),\n ('inclus', 4.110873864173311),\n ('superwealthi', 4.07753744390572)]"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "dem_rep_ratios.most_common()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the words are much more representative of what we might expect to see from a democrats twitter feed. The only word that I personally don't immediately understand is 'knock'. But the rest seem very appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[('keepamericagreat', -inf),\n ('scotu', -inf),\n ('schumer', -inf),\n ('irand', -inf),\n ('spous', -inf),\n ('immigrationact', -inf),\n ('karen', -inf),\n ('trumpwarroom', -inf),\n ('garland', -inf),\n ('schiff', -inf)]"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "list(reversed(dem_rep_ratios.most_common()))[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the words are also much more representative of what we might expect to see from a republican's twitter feed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "dem-to-rep ratio for 'rt' = -0.8560784784548614\ndem-to-rep ratio for 'great' = -1.0005043645276555\ndem-to-rep ratio for 'news' = -0.5290079428491812\ndem-to-rep ratio for 'wealth' = 2.272125885509337\ndem-to-rep ratio for 'health' = 1.0793809267402221\n"
    }
   ],
   "source": [
    "# 1 = democrat\n",
    "# -1 = republican\n",
    "# 0 = neutral\n",
    "print(\"dem-to-rep ratio for 'rt' = {}\".format(dem_rep_ratios[\"rt\"]))\n",
    "print(\"dem-to-rep ratio for 'great' = {}\".format(dem_rep_ratios[\"great\"]))\n",
    "print(\"dem-to-rep ratio for 'news' = {}\".format(dem_rep_ratios[\"news\"]))\n",
    "print(\"dem-to-rep ratio for 'wealth' = {}\".format(dem_rep_ratios[\"wealth\"]))\n",
    "print(\"dem-to-rep ratio for 'health' = {}\".format(dem_rep_ratios[\"health\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local library housing a custom neural net with two hidden layers\n",
    "import mfinchmods as mf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tw_Net - a near clone of the Senti_Net\n",
    "mlp = mf.Tw_Net(processed_tweets[:-1000],\n",
    "                labels[:-1000],\n",
    "                min_count=20,\n",
    "                polarity_cutoff=0.05,\n",
    "                learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "How much I've read:0.0% How fast I can read:(reviews/sec):0.0 #Correct:1 #Trained:1 Training Accuracy:100.%\nHow much I've read:10.0% How fast I can read:(reviews/sec):4534. #Correct:1956 #Trained:2501 Training Accuracy:78.2%\nHow much I've read:20.1% How fast I can read:(reviews/sec):4671. #Correct:4057 #Trained:5001 Training Accuracy:81.1%\nHow much I've read:30.2% How fast I can read:(reviews/sec):4757. #Correct:6188 #Trained:7501 Training Accuracy:82.4%\nHow much I've read:40.2% How fast I can read:(reviews/sec):4807. #Correct:8352 #Trained:10001 Training Accuracy:83.5%\nHow much I've read:50.3% How fast I can read:(reviews/sec):4837. #Correct:10513 #Trained:12501 Training Accuracy:84.0%\nHow much I've read:60.4% How fast I can read:(reviews/sec):4837. #Correct:12732 #Trained:15001 Training Accuracy:84.8%\nHow much I've read:70.5% How fast I can read:(reviews/sec):4852. #Correct:14955 #Trained:17501 Training Accuracy:85.4%\nHow much I've read:80.5% How fast I can read:(reviews/sec):4856. #Correct:17189 #Trained:20001 Training Accuracy:85.9%\nHow much I've read:90.6% How fast I can read:(reviews/sec):4863. #Correct:19424 #Trained:22501 Training Accuracy:86.3%\nHow much I've read:99.9% How fast I can read:(reviews/sec):4874. #Correct:21507 #Trained:24821 Training Accuracy:86.6%"
    }
   ],
   "source": [
    "mlp.train(processed_tweets[:-1000],labels[:-1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "How much I've read:99.8% How fast I can read:(reviews/sec):5426. #Correct:0 #Tested:999 Testing Accuracy:0.0%"
    }
   ],
   "source": [
    "# i messed up the internal print statement here, but the actual accuracy is 85.7% - we can see this in the 'result' print out\n",
    "results = mlp.predict(processed_tweets[-1000:-1],labels[-1000:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'a republican tweeted this': 'republican',\n 'a democrat tweeted this': 'democrat'}"
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "# results returns the overall predictions with pred on the left and label on the right\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tw_Net Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model Classification:\na republican tweeted this\n\n\nActual Label:\nrepublican\n\n\nProcessed Tweet:\nrt secondladi ’ begin look lot like christma vice presid ’ resid thank volunt help de…\n\n\nRaw Tweet\nRT @SecondLady: It’s beginning to look a lot like Christmas at the Vice President’s Residence! Thank you to the volunteers who helped to de…\n"
    }
   ],
   "source": [
    "print('Model Classification:')\n",
    "print(mlp.classify(processed_tweets[18]))\n",
    "print('\\n')\n",
    "print('Actual Label:')\n",
    "print(labels[18])\n",
    "print('\\n')\n",
    "print('Processed Tweet:')\n",
    "print(processed_tweets[18])\n",
    "print('\\n')\n",
    "print('Raw Tweet')\n",
    "print(tweets[18])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model Classification:\na democrat tweeted this\n\n\nActual Label:\ndemocrat\n\n\nProcessed Tweet:\nleast 32 million nurs caregiv food servic worker america dont access paid sick leav moral wrong coronaviru crisi make clear put u risk\n\n\nRaw Tweet\nAt least 32 million nurses, caregivers, and food service workers in America don't have access to any paid sick leave. \n\nIt's morally wrong and, as the coronavirus crisis makes clear, it puts us all at risk. https://t.co/b6ZTIhBWl8\n"
    }
   ],
   "source": [
    "print('Model Classification:')\n",
    "print(mlp.classify(processed_tweets[2]))\n",
    "print('\\n')\n",
    "print('Actual Label:')\n",
    "print(labels[2])\n",
    "print('\\n')\n",
    "print('Processed Tweet:')\n",
    "print(processed_tweets[2])\n",
    "print('\\n')\n",
    "print('Raw Tweet')\n",
    "print(tweets[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model Classification:\na democrat tweeted this\n\n\nActual Label:\ndemocrat\n\n\nProcessed Tweet:\nonward togeth end 2017 support six incred organ fight protect vote right make easier young divers candid get ballot get elect\n\n\nRaw Tweet\nOnward Together is ending 2017 by supporting six more incredible organizations fighting to protect voting rights and to make it easier for young, diverse candidates to get on the ballot and get elected.\n"
    }
   ],
   "source": [
    "print('Model Classification:')\n",
    "print(mlp.classify(processed_tweets[325]))\n",
    "print('\\n')\n",
    "print('Actual Label:')\n",
    "print(labels[325])\n",
    "print('\\n')\n",
    "print('Processed Tweet:')\n",
    "print(processed_tweets[325])\n",
    "print('\\n')\n",
    "print('Raw Tweet')\n",
    "print(tweets[325])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model Classification:\na republican tweeted this\n\n\nActual Label:\nrepublican\n\n\nProcessed Tweet:\namerica lost patriot humbl servant georg herbert walker bush heart heavi today also fill gratitud thought entir bush famili tonight – inspir georg barbara ’ exampl\n\n\nRaw Tweet\nAmerica has lost a patriot and humble servant in George Herbert Walker Bush. While our hearts are heavy today, they are also filled with gratitude. Our thoughts are with the entire Bush family tonight – and all who were inspired by George and Barbara’s example. https://t.co/g9OUPu2pjY\n"
    }
   ],
   "source": [
    "print('Model Classification:')\n",
    "print(mlp.classify(processed_tweets[2000]))\n",
    "print('\\n')\n",
    "print('Actual Label:')\n",
    "print(labels[2000])\n",
    "print('\\n')\n",
    "print('Processed Tweet:')\n",
    "print(processed_tweets[2000])\n",
    "print('\\n')\n",
    "print('Raw Tweet')\n",
    "print(tweets[2000])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37364bitanaconda3virtualenve0beec8455a449faa64632dc843014f3",
   "display_name": "Python 3.7.3 64-bit ('anaconda3': virtualenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}